{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation_leave_oneSite_out_Japanese_Reho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score,confusion_matrix\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Convolutional Neural Network : BASED ON https://www.biorxiv.org/content/10.1101/2019.12.17.879346v1\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.downsample = nn.AvgPool3d(2, stride=2, padding=0)\n",
    "        \n",
    "        self.CNNlayer = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=3, stride=1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv3d(64, 16, kernel_size=3, stride=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool3d(2)\n",
    "        )\n",
    "        \n",
    "        self.flat1 = nn.Linear(160000, 16)   \n",
    "        self.flat2 = nn.Linear(16, 1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x=self.downsample(x)\n",
    "        #print(f'avg-pool: {x.size()}\\n----------')\n",
    "        #print(f'number of nan in this layer = {torch.isnan(x).sum()}')\n",
    "        \n",
    "        x=self.CNNlayer(x)\n",
    "        #print(f'convolution1+2+maxpool: {x.size()} \\n----------')\n",
    "        \n",
    "        x=x.reshape(x.size(0), -1)\n",
    "        #print(f'reshape after cnn: {x.size()}\\n----------')\n",
    "        \n",
    "        x=F.elu(self.flat1(x))\n",
    "        #print(f'fully-connected1: {x.size()}\\n----------')\n",
    "                    \n",
    "        x=self.flat2(x)\n",
    "        #print(f'fully-connected2: {x.size()}\\n----------')\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lunch wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/zmohaghegh/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "!wandb login 390734ff44d817dbba59927d4eb542e564627b3b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funtion for preparaing summary measure for feeding to neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparaing_summary_measure(mdd_test_site_reho_load,control_test_site_reho_load):\n",
    "    \n",
    "    # load numpy \n",
    "    control_reho_zero_nan2= control_test_site_reho_load\n",
    "    mdd_reho_zero_nan2 = mdd_test_site_reho_load\n",
    "\n",
    "    # create empty numpy \n",
    "    control_reho_zero_nan3 =np.array(control_reho_zero_nan2)\n",
    "    mdd_reho_zero_nan3 = np.array(mdd_reho_zero_nan2)\n",
    "\n",
    "    # zero_nan_control\n",
    "    for i in range(len(control_test_site_reho_load)):    \n",
    "        control_reho_zero_nan3[i][0] =np.nan_to_num(control_test_site_reho_load[i][0],copy=True)\n",
    "        control_reho_zero_nan3[i][1] =np.nan_to_num(control_test_site_reho_load[i][1],copy=True)\n",
    "\n",
    "    # zero_nan_mdd\n",
    "    for i in range(len(mdd_test_site_reho_load)):    \n",
    "        mdd_reho_zero_nan3[i][0] =np.nan_to_num(mdd_test_site_reho_load[i][0],copy=True)\n",
    "        mdd_reho_zero_nan3[i][1] =np.nan_to_num(mdd_test_site_reho_load[i][1],copy=True)\n",
    "\n",
    "    # add one channel to zero nan\n",
    "    control_reho_4d_zero_nan = [[np.reshape(c[0], (1, 91, 109, 91)), c[1]] for c in control_reho_zero_nan3]\n",
    "    mdd_reho_4d_zero_nan = [[np.reshape(m[0], (1, 91, 109, 91)), m[1]] for m in mdd_reho_zero_nan3]\n",
    "\n",
    "    # concat mdd and contor data  \n",
    "    dataset_Japan_test_reho_zero_nan= ConcatDataset([control_reho_4d_zero_nan, mdd_reho_4d_zero_nan])\n",
    "    \n",
    "    #dataset_Japan_test_reho_zero_nan[10][0][0,:,54,45]\n",
    "    \n",
    "    return dataset_Japan_test_reho_zero_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Japanese IDs for each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COI_MDD=pd.read_csv('COI_MDD.csv')\n",
    "UTO_MDD=pd.read_csv('UTO_MDD.csv')\n",
    "HUH_MDD=pd.read_csv('HUH_MDD.csv')\n",
    "HKH_MDD=pd.read_csv('HKH_MDD.csv')\n",
    "HRC_MDD=pd.read_csv('HRC_MDD.csv')\n",
    "KUT_MDD=pd.read_csv('KUT_MDD.csv')\n",
    "\n",
    "MDD_sites=[COI_MDD,UTO_MDD,HUH_MDD,HKH_MDD,HRC_MDD,KUT_MDD]\n",
    "MDD_sites_concat=pd.concat([COI_MDD,UTO_MDD,HUH_MDD,HKH_MDD,HRC_MDD,KUT_MDD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COI_Control=pd.read_csv('COI_Control.csv')\n",
    "UTO_Control=pd.read_csv('UTO_Control.csv')\n",
    "HUH_Control=pd.read_csv('HUH_Control.csv')\n",
    "HKH_Control=pd.read_csv('HKH_Control.csv')\n",
    "HRC_Control=pd.read_csv('HRC_Control.csv')\n",
    "KUT_Control=pd.read_csv('KUT_Control.csv')\n",
    "\n",
    "Control_sites=[COI_Control,UTO_Control,HUH_Control,HKH_Control,HRC_Control,KUT_Control]\n",
    "Control_sites_concat=pd.concat([COI_Control,UTO_Control,HUH_Control,HKH_Control,HRC_Control,KUT_Control])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdd_base_path = '/dbstore/zmohaghegh/Japanese_subset/summary_measures/MDD_reho/ReHo_Normalised_z/'\n",
    "control_base_path = '/dbstore/zmohaghegh/Japanese_subset/summary_measures/Control_reho/ReHo_Normalised_z/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave on site out : Cross validation loop for each Site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COI\n",
      "loading test dataset\n",
      "test MDD size : 71\n",
      "test Control size : 71\n",
      "concating train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zmohaghegh/venv/lib64/python3.6/site-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n",
      "/data/zmohaghegh/venv/lib64/python3.6/site-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset size : 142\n",
      "loading train dataset\n",
      "train MDD size : 184\n",
      "train Control size : 180\n",
      "concating train dataset\n",
      "train dataset size : 364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzahramhn\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">genial-frog-25</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/zahramhn/Leave-one-site-out-2-japanese-reho\" target=\"_blank\">https://wandb.ai/zahramhn/Leave-one-site-out-2-japanese-reho</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/zahramhn/Leave-one-site-out-2-japanese-reho/runs/37itxfgd\" target=\"_blank\">https://wandb.ai/zahramhn/Leave-one-site-out-2-japanese-reho/runs/37itxfgd</a><br/>\n",
       "                Run data is saved locally in <code>/data/zmohaghegh/TempStats_3D-CNN/wandb/run-20210526_134755-37itxfgd</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "*********Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zmohaghegh/venv/lib64/python3.6/site-packages/torch/autograd/__init__.py:147: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss= 0.07450295973451239\n",
      "train Acc= 52.233676975945016\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :46.57534246575342\n",
      "valid_loss: 0.08012429626477295\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 2\n",
      "train loss= 0.06539555457823829\n",
      "train Acc= 61.512027491408936\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :67.12328767123287\n",
      "valid_loss: 0.07570957140461582\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 3\n",
      "train loss= 0.05815341912050558\n",
      "train Acc= 74.22680412371135\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :60.273972602739725\n",
      "valid_loss: 0.07080329193701439\n",
      "validation process has finished\n",
      "*********Starting epoch 4\n",
      "train loss= 0.04365787747923492\n",
      "train Acc= 80.06872852233677\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :63.013698630136986\n",
      "valid_loss: 0.0723703653813166\n",
      "validation process has finished\n",
      "*********Starting epoch 5\n",
      "train loss= 0.03336773710858818\n",
      "train Acc= 85.2233676975945\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :63.013698630136986\n",
      "valid_loss: 0.08540095455945458\n",
      "validation process has finished\n",
      "*********Starting epoch 6\n",
      "train loss= 0.017206800726884474\n",
      "train Acc= 95.18900343642612\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :63.013698630136986\n",
      "valid_loss: 0.09415735588883292\n",
      "validation process has finished\n",
      "*********Starting epoch 7\n",
      "train loss= 0.007043447971925898\n",
      "train Acc= 99.65635738831615\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :58.9041095890411\n",
      "valid_loss: 0.09095325237923317\n",
      "validation process has finished\n",
      "*********Starting epoch 8\n",
      "train loss= 0.002740169160173299\n",
      "train Acc= 99.65635738831615\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :61.64383561643836\n",
      "valid_loss: 0.10249878836727788\n",
      "validation process has finished\n",
      "*********Starting epoch 9\n",
      "train loss= 0.0013602160959947651\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :60.273972602739725\n",
      "valid_loss: 0.11054262642709309\n",
      "validation process has finished\n",
      "*********Starting epoch 10\n",
      "train loss= 0.0008857041647233747\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :58.9041095890411\n",
      "valid_loss: 0.10901123057728306\n",
      "validation process has finished\n",
      "Accuracy for fold 0: 58 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "*********Starting epoch 1\n",
      "train loss= 0.07290902702696103\n",
      "train Acc= 51.202749140893474\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :57.534246575342465\n",
      "valid_loss: 0.07416631949493656\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 2\n",
      "train loss= 0.061439253090278645\n",
      "train Acc= 71.8213058419244\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :45.205479452054796\n",
      "valid_loss: 0.08843912081942042\n",
      "validation process has finished\n",
      "*********Starting epoch 3\n",
      "train loss= 0.05013111735236689\n",
      "train Acc= 77.66323024054982\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :53.42465753424658\n",
      "valid_loss: 0.08647649098051947\n",
      "validation process has finished\n",
      "*********Starting epoch 4\n",
      "train loss= 0.034985719238896526\n",
      "train Acc= 90.37800687285224\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :64.38356164383562\n",
      "valid_loss: 0.09401663274791144\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 5\n",
      "train loss= 0.05028268372012175\n",
      "train Acc= 81.09965635738831\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :61.64383561643836\n",
      "valid_loss: 0.08848808884453736\n",
      "validation process has finished\n",
      "*********Starting epoch 6\n",
      "train loss= 0.0240876162572225\n",
      "train Acc= 93.81443298969072\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :64.38356164383562\n",
      "valid_loss: 0.08829970326313612\n",
      "validation process has finished\n",
      "*********Starting epoch 7\n",
      "train loss= 0.01772806320147006\n",
      "train Acc= 91.40893470790378\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :61.64383561643836\n",
      "valid_loss: 0.11744669983110421\n",
      "validation process has finished\n",
      "*********Starting epoch 8\n",
      "train loss= 0.0038953540955736317\n",
      "train Acc= 99.65635738831615\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :64.38356164383562\n",
      "valid_loss: 0.10037837096833746\n",
      "validation process has finished\n",
      "*********Starting epoch 9\n",
      "train loss= 0.0015071764477679664\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :63.013698630136986\n",
      "valid_loss: 0.12537046927464124\n",
      "validation process has finished\n",
      "*********Starting epoch 10\n",
      "train loss= 0.0009053912835508559\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :63.013698630136986\n",
      "valid_loss: 0.14155550061827668\n",
      "validation process has finished\n",
      "Accuracy for fold 1: 63 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "*********Starting epoch 1\n",
      "train loss= 0.07406322913282236\n",
      "train Acc= 56.70103092783505\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :46.57534246575342\n",
      "valid_loss: 0.07616319797163001\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 2\n",
      "train loss= 0.06689184349322902\n",
      "train Acc= 62.88659793814433\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :47.945205479452056\n",
      "valid_loss: 0.07555862697610273\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 3\n",
      "train loss= 0.058805308372861485\n",
      "train Acc= 71.47766323024055\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :54.794520547945204\n",
      "valid_loss: 0.08477785640367214\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 4\n",
      "train loss= 0.04578927686827856\n",
      "train Acc= 80.41237113402062\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :47.945205479452056\n",
      "valid_loss: 0.11739073345973737\n",
      "validation process has finished\n",
      "*********Starting epoch 5\n",
      "train loss= 0.04331096192049254\n",
      "train Acc= 76.28865979381443\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :54.794520547945204\n",
      "valid_loss: 0.0887363421730731\n",
      "validation process has finished\n",
      "*********Starting epoch 6\n",
      "train loss= 0.02742621302165408\n",
      "train Acc= 88.65979381443299\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :56.16438356164384\n",
      "valid_loss: 0.10201334988985926\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 7\n",
      "train loss= 0.012699142326445303\n",
      "train Acc= 96.56357388316151\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :56.16438356164384\n",
      "valid_loss: 0.11879353472324888\n",
      "validation process has finished\n",
      "*********Starting epoch 8\n",
      "train loss= 0.004952560686753648\n",
      "train Acc= 98.96907216494846\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :57.534246575342465\n",
      "valid_loss: 0.13330142378023002\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 9\n",
      "train loss= 0.0020943208042785997\n",
      "train Acc= 99.65635738831615\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :54.794520547945204\n",
      "valid_loss: 0.17975397932526052\n",
      "validation process has finished\n",
      "*********Starting epoch 10\n",
      "train loss= 0.001285454313791041\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :49.31506849315068\n",
      "valid_loss: 0.16467078843126953\n",
      "validation process has finished\n",
      "Accuracy for fold 2: 49 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "*********Starting epoch 1\n",
      "train loss= 0.07287695475414198\n",
      "train Acc= 50.85910652920962\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :52.054794520547944\n",
      "valid_loss: 0.07801684692050731\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 2\n",
      "train loss= 0.06757462596762191\n",
      "train Acc= 65.63573883161511\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :60.273972602739725\n",
      "valid_loss: 0.07481791279205945\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 3\n",
      "train loss= 0.055076729362040014\n",
      "train Acc= 78.35051546391753\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :52.054794520547944\n",
      "valid_loss: 0.0779449268010979\n",
      "validation process has finished\n",
      "*********Starting epoch 4\n",
      "train loss= 0.04234156990193676\n",
      "train Acc= 82.81786941580756\n",
      "Training process has finished.\n",
      "Starting testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_acc :60.273972602739725\n",
      "valid_loss: 0.0746230097606755\n",
      "validation process has finished\n",
      "*********Starting epoch 5\n",
      "train loss= 0.024433232182544472\n",
      "train Acc= 92.43986254295532\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :58.9041095890411\n",
      "valid_loss: 0.08684062222549328\n",
      "validation process has finished\n",
      "*********Starting epoch 6\n",
      "train loss= 0.008535049462364754\n",
      "train Acc= 98.96907216494846\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :65.75342465753425\n",
      "valid_loss: 0.10619095512406129\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 7\n",
      "train loss= 0.003674442391578086\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :58.9041095890411\n",
      "valid_loss: 0.1299706517272936\n",
      "validation process has finished\n",
      "*********Starting epoch 8\n",
      "train loss= 0.0017047476285293073\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :63.013698630136986\n",
      "valid_loss: 0.1238276960902813\n",
      "validation process has finished\n",
      "*********Starting epoch 9\n",
      "train loss= 0.000980855714265839\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :60.273972602739725\n",
      "valid_loss: 0.12813630044623578\n",
      "validation process has finished\n",
      "*********Starting epoch 10\n",
      "train loss= 0.0006087496682060428\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :58.9041095890411\n",
      "valid_loss: 0.13053528438246131\n",
      "validation process has finished\n",
      "Accuracy for fold 3: 58 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "*********Starting epoch 1\n",
      "train loss= 0.0722702229106333\n",
      "train Acc= 49.31506849315068\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :54.166666666666664\n",
      "valid_loss: 0.07671229587881573\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 2\n",
      "train loss= 0.06682515494893695\n",
      "train Acc= 66.78082191780823\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :48.611111111111114\n",
      "valid_loss: 0.0790888030545127\n",
      "validation process has finished\n",
      "*********Starting epoch 3\n",
      "train loss= 0.05513922805942422\n",
      "train Acc= 79.10958904109589\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :48.611111111111114\n",
      "valid_loss: 0.07911649605122614\n",
      "validation process has finished\n",
      "*********Starting epoch 4\n",
      "train loss= 0.04222470647070055\n",
      "train Acc= 86.3013698630137\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :52.77777777777778\n",
      "valid_loss: 0.09106456366132906\n",
      "validation process has finished\n",
      "*********Starting epoch 5\n",
      "train loss= 0.025853108036339358\n",
      "train Acc= 93.15068493150685\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :50.0\n",
      "valid_loss: 0.09036756645866478\n",
      "validation process has finished\n",
      "*********Starting epoch 6\n",
      "train loss= 0.013247887075284065\n",
      "train Acc= 97.26027397260275\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :62.5\n",
      "valid_loss: 0.09609637585213465\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 7\n",
      "train loss= 0.00474488697448358\n",
      "train Acc= 99.31506849315069\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :54.166666666666664\n",
      "valid_loss: 0.10034311829772934\n",
      "validation process has finished\n",
      "*********Starting epoch 8\n",
      "train loss= 0.0019704723427853674\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :51.388888888888886\n",
      "valid_loss: 0.11959648687405883\n",
      "validation process has finished\n",
      "*********Starting epoch 9\n",
      "train loss= 0.0009247212789414062\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :51.388888888888886\n",
      "valid_loss: 0.11778634269121345\n",
      "validation process has finished\n",
      "*********Starting epoch 10\n",
      "train loss= 0.0006801788142214983\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :50.0\n",
      "valid_loss: 0.1506061539590804\n",
      "validation process has finished\n",
      "Accuracy for fold 4: 50 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR japanese reho site COI 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 58.9041095890411 %\n",
      "Fold 1: 63.013698630136986 %\n",
      "Fold 2: 49.31506849315068 %\n",
      "Fold 3: 58.9041095890411 %\n",
      "Fold 4: 50.0 %\n",
      "Average: 56.02739726027397 %\n",
      "Start TEST FOR FOLD 0\n",
      "test_Acc_CV\": 47.183098591549296\n",
      "Loss CV ReHo : 0.0794634940554577\n",
      "Start TEST FOR FOLD 1\n",
      "test_Acc_CV\": 48.59154929577465\n",
      "Loss CV ReHo : 0.0984590143439909\n",
      "Start TEST FOR FOLD 2\n",
      "test_Acc_CV\": 49.29577464788732\n",
      "Loss CV ReHo : 0.12050801940796126\n",
      "Start TEST FOR FOLD 3\n",
      "test_Acc_CV\": 49.29577464788732\n",
      "Loss CV ReHo : 0.11946259979287067\n",
      "Start TEST FOR FOLD 4\n",
      "test_Acc_CV\": 50.0\n",
      "Loss CV ReHo : 0.10598165185447561\n",
      " Site name #################### : COI\n",
      " Average Balance ACC japan ReHo = 48.87323943661972\n",
      "standard deviation :0.9552577441021495\n",
      " Average F1_score japan ReHo = 0.4383980158815469\n",
      "standard deviation :0.04395381562793778\n",
      "UTO\n",
      "loading test dataset\n",
      "test MDD size : 62\n",
      "test Control size : 62\n",
      "concating train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zmohaghegh/venv/lib64/python3.6/site-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n",
      "/data/zmohaghegh/venv/lib64/python3.6/site-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset size : 124\n",
      "loading train dataset\n",
      "train MDD size : 193\n",
      "train Control size : 189\n",
      "concating train dataset\n",
      "train dataset size : 382\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:37itxfgd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35072<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/data/zmohaghegh/TempStats_3D-CNN/wandb/run-20210526_134755-37itxfgd/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/data/zmohaghegh/TempStats_3D-CNN/wandb/run-20210526_134755-37itxfgd/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch_cv</td><td>9</td></tr><tr><td>train_Loss_cv</td><td>0.00068</td></tr><tr><td>train_acc_cv</td><td>100.0</td></tr><tr><td>_runtime</td><td>12661</td></tr><tr><td>_timestamp</td><td>1622042337</td></tr><tr><td>_step</td><td>105</td></tr><tr><td>validation_acc_fold_0</td><td>58.90411</td></tr><tr><td>validation_Loss_fold_0</td><td>0.10901</td></tr><tr><td>validation_acc_fold_1</td><td>63.0137</td></tr><tr><td>validation_Loss_fold_1</td><td>0.14156</td></tr><tr><td>validation_acc_fold_2</td><td>49.31507</td></tr><tr><td>validation_Loss_fold_2</td><td>0.16467</td></tr><tr><td>validation_acc_fold_3</td><td>58.90411</td></tr><tr><td>validation_Loss_fold_3</td><td>0.13054</td></tr><tr><td>validation_acc_fold_4</td><td>50.0</td></tr><tr><td>validation_Loss_fold_4</td><td>0.15061</td></tr><tr><td>test_balanced_Acc_Site_COI</td><td>0.5</td></tr><tr><td>test_F1_score_Site_COI</td><td>0.43242</td></tr><tr><td>test_balanced_Acc_Average</td><td>48.87324</td></tr><tr><td>test_F1_score_Average</td><td>0.4384</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch_cv</td><td>▁▂▃▃▅▆▆▇▁▂▃▃▅▆▆▇▁▂▃▃▅▆▆▇▁▂▃▃▅▆▆▇▁▂▃▃▅▆▆█</td></tr><tr><td>train_Loss_cv</td><td>█▇▆▅▃▂▁▁█▇▆▄▃▃▁▁█▇▇▅▄▂▁▁█▇▆▅▂▁▁▁█▇▆▅▂▁▁▁</td></tr><tr><td>train_acc_cv</td><td>▁▃▄▅▇███▁▄▅▇▇▇██▂▃▄▅▆███▁▃▅▆████▁▃▅▆████</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>validation_acc_fold_0</td><td>▁█▆▇▇▇▅▆▆▅</td></tr><tr><td>validation_Loss_fold_0</td><td>▃▂▁▁▄▅▅▇██</td></tr><tr><td>validation_acc_fold_1</td><td>▆▁▄█▇█▇███</td></tr><tr><td>validation_Loss_fold_1</td><td>▁▂▂▃▂▂▅▄▆█</td></tr><tr><td>validation_acc_fold_2</td><td>▁▂▆▂▆▇▇█▆▃</td></tr><tr><td>validation_Loss_fold_2</td><td>▁▁▂▄▂▃▄▅█▇</td></tr><tr><td>validation_acc_fold_3</td><td>▁▅▁▅▅█▅▇▅▅</td></tr><tr><td>validation_Loss_fold_3</td><td>▁▁▁▁▃▅█▇██</td></tr><tr><td>validation_acc_fold_4</td><td>▄▁▁▃▂█▄▂▂▂</td></tr><tr><td>validation_Loss_fold_4</td><td>▁▁▁▂▂▃▃▅▅█</td></tr><tr><td>test_balanced_Acc_Site_COI</td><td>▁▄▆▆█</td></tr><tr><td>test_F1_score_Site_COI</td><td>▁▅█▇▅</td></tr><tr><td>test_balanced_Acc_Average</td><td>▁</td></tr><tr><td>test_F1_score_Average</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">genial-frog-25</strong>: <a href=\"https://wandb.ai/zahramhn/Leave-one-site-out-2-japanese-reho/runs/37itxfgd\" target=\"_blank\">https://wandb.ai/zahramhn/Leave-one-site-out-2-japanese-reho/runs/37itxfgd</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:37itxfgd). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">gentle-lake-26</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/zahramhn/Leave-one-site-out-2-japanese-reho\" target=\"_blank\">https://wandb.ai/zahramhn/Leave-one-site-out-2-japanese-reho</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/zahramhn/Leave-one-site-out-2-japanese-reho/runs/3uieehtf\" target=\"_blank\">https://wandb.ai/zahramhn/Leave-one-site-out-2-japanese-reho/runs/3uieehtf</a><br/>\n",
       "                Run data is saved locally in <code>/data/zmohaghegh/TempStats_3D-CNN/wandb/run-20210526_171913-3uieehtf</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "*********Starting epoch 1\n",
      "train loss= 0.07196704249830187\n",
      "train Acc= 49.50819672131148\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :53.246753246753244\n",
      "valid_loss: 0.0715308927370178\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 2\n",
      "train loss= 0.06360946894372833\n",
      "train Acc= 67.21311475409836\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :53.246753246753244\n",
      "valid_loss: 0.07445665808220475\n",
      "validation process has finished\n",
      "*********Starting epoch 3\n",
      "train loss= 0.05055324329967333\n",
      "train Acc= 77.04918032786885\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :50.64935064935065\n",
      "valid_loss: 0.1108937106798008\n",
      "validation process has finished\n",
      "*********Starting epoch 4\n",
      "train loss= 0.04489155337144579\n",
      "train Acc= 80.65573770491804\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :58.44155844155844\n",
      "valid_loss: 0.07730140684978797\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 5\n",
      "train loss= 0.02140316466048125\n",
      "train Acc= 92.45901639344262\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :62.33766233766234\n",
      "valid_loss: 0.0973585893058091\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 6\n",
      "train loss= 0.011864577280642361\n",
      "train Acc= 98.36065573770492\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :59.74025974025974\n",
      "valid_loss: 0.09729809565857771\n",
      "validation process has finished\n",
      "*********Starting epoch 7\n",
      "train loss= 0.006139898955530427\n",
      "train Acc= 99.01639344262296\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :57.142857142857146\n",
      "valid_loss: 0.10692124134174906\n",
      "validation process has finished\n",
      "*********Starting epoch 8\n",
      "train loss= 0.002033019899436612\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :54.54545454545455\n",
      "valid_loss: 0.12359846905139042\n",
      "validation process has finished\n",
      "*********Starting epoch 9\n",
      "train loss= 0.0012942154953947708\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :50.64935064935065\n",
      "valid_loss: 0.1342949020449845\n",
      "validation process has finished\n",
      "*********Starting epoch 10\n",
      "train loss= 0.0005543645661427142\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :51.94805194805195\n",
      "valid_loss: 0.1390537584500154\n",
      "validation process has finished\n",
      "Accuracy for fold 0: 51 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "*********Starting epoch 1\n",
      "train loss= 0.07192943234454599\n",
      "train Acc= 48.85245901639344\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :41.55844155844156\n",
      "valid_loss: 0.07920364096032363\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 2\n",
      "train loss= 0.06563182855651065\n",
      "train Acc= 61.31147540983606\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :62.33766233766234\n",
      "valid_loss: 0.06971411521619465\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 3\n",
      "train loss= 0.052485739728500506\n",
      "train Acc= 74.75409836065573\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :53.246753246753244\n",
      "valid_loss: 0.07708475259947248\n",
      "validation process has finished\n",
      "*********Starting epoch 4\n",
      "train loss= 0.03600569858124929\n",
      "train Acc= 84.91803278688525\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :54.54545454545455\n",
      "valid_loss: 0.0995034046197122\n",
      "validation process has finished\n",
      "*********Starting epoch 5\n",
      "train loss= 0.02877407437483288\n",
      "train Acc= 87.8688524590164\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :55.84415584415584\n",
      "valid_loss: 0.1328900613532138\n",
      "validation process has finished\n",
      "*********Starting epoch 6\n",
      "train loss= 0.025460063598139775\n",
      "train Acc= 88.52459016393442\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :61.03896103896104\n",
      "valid_loss: 0.0998442020774954\n",
      "validation process has finished\n",
      "*********Starting epoch 7\n",
      "train loss= 0.008516551067328815\n",
      "train Acc= 98.36065573770492\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :58.44155844155844\n",
      "valid_loss: 0.12549071484425936\n",
      "validation process has finished\n",
      "*********Starting epoch 8\n",
      "train loss= 0.004050850563179601\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :55.84415584415584\n",
      "valid_loss: 0.1355397270826926\n",
      "validation process has finished\n",
      "*********Starting epoch 9\n",
      "train loss= 0.0013627042803328018\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :57.142857142857146\n",
      "valid_loss: 0.14384837932465494\n",
      "validation process has finished\n",
      "*********Starting epoch 10\n",
      "train loss= 0.0008019061838580822\n",
      "train Acc= 100.0\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :58.44155844155844\n",
      "valid_loss: 0.15411524778041485\n",
      "validation process has finished\n",
      "Accuracy for fold 1: 58 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "*********Starting epoch 1\n",
      "train loss= 0.07102062240642598\n",
      "train Acc= 51.96078431372549\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :55.26315789473684\n",
      "valid_loss: 0.07166702963562956\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 2\n",
      "train loss= 0.06315495511979485\n",
      "train Acc= 70.58823529411765\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :59.21052631578947\n",
      "valid_loss: 0.06782173355122417\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 3\n",
      "train loss= 0.054716964546853986\n",
      "train Acc= 75.16339869281046\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :63.1578947368421\n",
      "valid_loss: 0.06817586653781693\n",
      "Saving best valid -trained model.\n",
      "validation process has finished\n",
      "*********Starting epoch 4\n",
      "train loss= 0.040268809904662355\n",
      "train Acc= 84.9673202614379\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :61.8421052631579\n",
      "valid_loss: 0.0694440760437691\n",
      "validation process has finished\n",
      "*********Starting epoch 5\n",
      "train loss= 0.03546445443163726\n",
      "train Acc= 86.27450980392157\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :57.89473684210526\n",
      "valid_loss: 0.07763478325250371\n",
      "validation process has finished\n",
      "*********Starting epoch 6\n",
      "train loss= 0.01517554936108384\n",
      "train Acc= 96.07843137254902\n",
      "Training process has finished.\n",
      "Starting testing\n",
      "valid_acc :59.21052631578947\n",
      "valid_loss: 0.09122255493215663\n",
      "validation process has finished\n",
      "*********Starting epoch 7\n"
     ]
    }
   ],
   "source": [
    "for site_num, site in enumerate(MDD_sites):\n",
    "    site_name= site['site'][0]\n",
    "    \n",
    "    print(site_name)\n",
    "    ##################### load test ######################\n",
    "    print('loading test dataset')\n",
    "    \n",
    "    ID_test_MDD=[]\n",
    "    for i in range(len(site['participants_id'])):\n",
    "        ID_test_MDD.append(site['participants_id'][i])\n",
    "    print(f'test MDD size : {len(ID_test_MDD)}')\n",
    "    \n",
    "    Control_test= Control_sites[site_num] \n",
    "    ID_test_Control=[]\n",
    "    for j in range(len(Control_test['participants_id'])):\n",
    "        ID_test_Control.append(Control_test['participants_id'][j])\n",
    "    print(f'test Control size : {len(ID_test_Control)}')\n",
    "    \n",
    "    test_site_mdd_file_path = [mdd_base_path + f'ReHo_z_{test_ids_MDD}.nii' for test_ids_MDD in ID_test_MDD]\n",
    "    test_site_control_file_path = [control_base_path + f'ReHo_z_{test_ids_Control}.nii' for test_ids_Control in ID_test_Control]\n",
    "\n",
    "    mdd_test_site_reho_load = [[nib.load(m).get_fdata(),1] for m in test_site_mdd_file_path]\n",
    "    control_test_site_reho_load = [[nib.load(c).get_fdata(),0] for c in test_site_control_file_path]\n",
    "    \n",
    "    # prepare test data for feeding to network\n",
    "    print('concating train dataset')\n",
    "    test_dataset_cv = preparaing_summary_measure(mdd_test_site_reho_load, control_test_site_reho_load) \n",
    "    print(f'test dataset size : {len(test_dataset_cv)}')\n",
    "\n",
    "    ##################### load train ######################\n",
    "    print('loading train dataset')\n",
    "    \n",
    "    ID_train_MDD=[]\n",
    "    for ids in MDD_sites_concat['participants_id']:\n",
    "        if ids not in ID_test_MDD:\n",
    "            ID_train_MDD.append(ids)\n",
    "    print(f'train MDD size : {len(ID_train_MDD)}')\n",
    "    \n",
    "    ID_train_Control=[]\n",
    "    for ids in Control_sites_concat['participants_id']:\n",
    "        if ids not in ID_test_Control:\n",
    "            ID_train_Control.append(ids)\n",
    "    print(f'train Control size : {len(ID_train_Control)}')\n",
    "            \n",
    "    \n",
    "    train_site_mdd_file_path = [mdd_base_path + f'ReHo_z_{train_ids_MDD}.nii' for train_ids_MDD in ID_train_MDD]\n",
    "    train_site_control_file_path = [control_base_path + f'ReHo_z_{train_ids_Control}.nii' for train_ids_Control in ID_train_Control]\n",
    "    \n",
    "    mdd_train_site_reho_load = [[nib.load(m).get_fdata(),1] for m in train_site_mdd_file_path]\n",
    "    control_train_site_reho_load = [[nib.load(c).get_fdata(),0] for c in train_site_control_file_path]\n",
    "    \n",
    "    # prepare train data for feeding to network\n",
    "    print('concating train dataset')\n",
    "    train_dataset_cv = preparaing_summary_measure(mdd_train_site_reho_load,control_train_site_reho_load)\n",
    "    print(f'train dataset size : {len(train_dataset_cv)}')\n",
    "    \n",
    "    ######################################################################################################\n",
    "    \n",
    "    wandb.init(project='Leave-one-site-out-2-japanese-reho')\n",
    "\n",
    "    ############################### train and validation loop CV  ########################################\n",
    "    k_folds = 5\n",
    "    kfold_results = {}\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "    #torch.manual_seed(42)\n",
    "    num_epochs = 10\n",
    "    batch_size = 10\n",
    "    learning_rate= 0.001\n",
    "\n",
    "    #Define a Loss function \n",
    "    loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(train_dataset_cv)):\n",
    "        best_loss_cv= None\n",
    "\n",
    "        print(f\"FOLD {fold}\\n--------------------------------\")\n",
    "\n",
    "        # Sample elements randomly from a given list of ids,\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)\n",
    "\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset_cv, batch_size=batch_size, sampler=train_subsampler)\n",
    "        valid_loader = torch.utils.data.DataLoader(train_dataset_cv, batch_size=batch_size, sampler=valid_subsampler)\n",
    "\n",
    "        #define network\n",
    "        network = ConvNet()\n",
    "        network = network.double()\n",
    "\n",
    "        # create our optimizer\n",
    "        optimizer = optim.SGD(network.parameters(), momentum=0.9, lr = learning_rate, weight_decay=1e-3)\n",
    "\n",
    "        # in the training loop:\n",
    "\n",
    "        network.train() # prepare model for training\n",
    "\n",
    "        for epoch in range(0, num_epochs):\n",
    "            print(f'*********Starting epoch {epoch+1}')\n",
    "\n",
    "            train_loss_cv = 0\n",
    "            total =0\n",
    "            correct=0\n",
    "\n",
    "            # train model/network \n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "                #print(f'train {i}')\n",
    "\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data\n",
    "\n",
    "                # zero the gradient buffers\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward pass\n",
    "                outputs = network(inputs)\n",
    "\n",
    "                # print(outputs.size)\n",
    "                outputss=outputs.squeeze(1) #### [10,1] ---> [10]\n",
    "\n",
    "                # prediction \n",
    "                predicted = outputss.data > 0.0\n",
    "\n",
    "                labels=labels.double()\n",
    "\n",
    "                #calcuate loss/error\n",
    "                loss = loss_function(outputss, labels)\n",
    "\n",
    "                # backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Does the update , gradient descent\n",
    "                optimizer.step() \n",
    "\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                train_loss_cv += loss.item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            wandb.log({\"epoch_cv\": epoch , \"train_Loss_cv\": train_loss_cv/total, \"train_acc_cv\": 100 * correct / total })\n",
    "\n",
    "            print(f'train loss= {train_loss_cv/total}')\n",
    "            print(f'train Acc= {100 * correct / total}')\n",
    "\n",
    "\n",
    "            print('Training process has finished.')\n",
    "            print('Starting testing')\n",
    "\n",
    "            # validate the network using the validation data, for this fold\n",
    "            correct= 0\n",
    "            total = 0\n",
    "            valid_loss_cv=0\n",
    "\n",
    "            network.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(valid_loader, 0):\n",
    "                    #print(f'test {i}')\n",
    "\n",
    "                    inputs, lables = data\n",
    "\n",
    "                    outputs = network(inputs)\n",
    "\n",
    "                    outputss=outputs.squeeze(1) #[10,1] ---> [10]\n",
    "                    lables=lables.double()\n",
    "\n",
    "                    # prediction \n",
    "                    predicted = outputss.data > 0.0\n",
    "\n",
    "                    loss = loss_function(outputss, lables)\n",
    "\n",
    "                    valid_loss_cv += loss.item()\n",
    "                    total += lables.size(0)\n",
    "                    correct += (predicted == lables).sum().item()\n",
    "\n",
    "            wandb.log({ f\"validation_acc_fold_{fold}\": 100 * correct /total, f\"validation_Loss_fold_{fold}\": valid_loss_cv/total })\n",
    "\n",
    "            current_valid_loss_cv = 100 * correct /total\n",
    "\n",
    "            print(f'valid_acc :{100 * correct /total}')\n",
    "            print(f'valid_loss: {valid_loss_cv/total}')\n",
    "\n",
    "            if not best_loss_cv or best_loss_cv < current_valid_loss_cv:\n",
    "                best_loss_cv = current_valid_loss_cv\n",
    "\n",
    "                print('Saving best valid -trained model.')\n",
    "                path_best_loss_reho = f'/data/zmohaghegh/TempStats_3D-CNN/leave_one_site_out_best_model_reho/model-japanese_best-reho-fold-{fold}.pth'\n",
    "                torch.save(network.state_dict(), path_best_loss_reho )\n",
    "\n",
    "            print('validation process has finished')\n",
    "\n",
    "        print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "        print('--------------------------------')\n",
    "\n",
    "        kfold_results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "    ############################## Result of Validation for each fold ##################################\n",
    "\n",
    "    print(f\"K-FOLD CROSS VALIDATION RESULTS FOR japanese reho site {site_name} {k_folds} FOLDS\\n--------------------------------\")\n",
    "    _sum = 0.0\n",
    "\n",
    "    for key, value in kfold_results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        _sum += value\n",
    "\n",
    "    print(f'Average: {_sum/len(kfold_results.items())} %')\n",
    "\n",
    "    ############################### Test loop for Cross validation #######################################\n",
    "    \n",
    "    test_loader  = torch.utils.data.DataLoader(test_dataset_cv , batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    bal_acc_fold=[]\n",
    "    F1_score_fold=[]\n",
    "\n",
    "    for k in np.arange(5): \n",
    "\n",
    "        print(f'Start TEST FOR FOLD {k}')\n",
    "\n",
    "        path_fold = f'/data/zmohaghegh/TempStats_3D-CNN/leave_one_site_out_best_model_reho/model-japanese_best-reho-fold-{k}.pth'\n",
    "\n",
    "        network.load_state_dict(torch.load(path_fold))\n",
    "\n",
    "        test_loss_cv=0\n",
    "        total = 0\n",
    "        correct=0\n",
    "\n",
    "        F1_labels=[]\n",
    "        F1_pred=[]\n",
    "\n",
    "        network.eval() # prepare model for test and evaluation\n",
    "\n",
    "        with torch.no_grad():\n",
    "            #print('Start testing CV...')\n",
    "            for i, data in enumerate(test_loader, 0):\n",
    "                #print(f'test {i}')\n",
    "\n",
    "                inputs, lables = data\n",
    "\n",
    "                outputs = network(inputs)\n",
    "\n",
    "                lables=lables.double()\n",
    "                outputss=outputs.squeeze(1) #[10,1] ---> [10]\n",
    "\n",
    "                #do the prediction \n",
    "                predicted = outputss.data > 0.0\n",
    "\n",
    "                #calculate loss\n",
    "                loss = loss_function(outputss, lables)\n",
    "\n",
    "                test_loss_cv += loss.item()\n",
    "                correct += (predicted == lables).sum().item()\n",
    "                total += lables.size(0)\n",
    "\n",
    "                if i==0:\n",
    "                    F1_labels=lables.int().numpy()\n",
    "                    F1_pred=predicted.int().numpy()\n",
    "                else:\n",
    "                    F1_labels= np.concatenate((F1_labels, lables.int().numpy()))\n",
    "                    F1_pred = np.concatenate((F1_pred, predicted.int().numpy()))\n",
    "\n",
    "        acc = accuracy_score(F1_labels, F1_pred)\n",
    "        bal_acc= balanced_accuracy_score(F1_labels, F1_pred)\n",
    "\n",
    "        F1_Score = f1_score(F1_labels, F1_pred, average='weighted')\n",
    "        #tn, fp, fn, tp = confusion_matrix(F1_labels, F1_pred).ravel()\n",
    "\n",
    "        F1_score_fold.append(F1_Score)\n",
    "        bal_acc_fold.append(bal_acc)\n",
    "\n",
    "        wandb.log({f\"test_balanced_Acc_Site_{site_name}\":bal_acc,f\"test_F1_score_Site_{site_name}\" :F1_Score})\n",
    "\n",
    "        print(f'test_Acc_CV\": {100 * correct /total}')\n",
    "        print(f'Loss CV ReHo : {test_loss_cv/total}')\n",
    "\n",
    "\n",
    "\n",
    "    ############################### Result of test loop average  #######################################       \n",
    "    \n",
    "    F1_score_avg= sum(F1_score_fold)/len(F1_score_fold)\n",
    "    F1_score_std= statistics.pstdev(F1_score_fold)\n",
    "    bal_acc_avg = 100 * (sum(bal_acc_fold)/len(bal_acc_fold))\n",
    "    bal_acc_std = 100* statistics.pstdev(bal_acc_fold)\n",
    "\n",
    "    print(f' Site name #################### : {site_name}')\n",
    "    print(f' Average Balance ACC japan ReHo = {bal_acc_avg}')\n",
    "    print(f'standard deviation :{bal_acc_std}')\n",
    "    print(f' Average F1_score japan ReHo = { F1_score_avg}')\n",
    "    print(f'standard deviation :{F1_score_std}')\n",
    "    \n",
    "    wandb.log({ f\"test_balanced_Acc_Average\": bal_acc_avg, f\"test_F1_score_Average\":F1_score_avg})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
